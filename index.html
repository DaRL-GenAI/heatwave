<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" href="./images/shadow-demo.gif"/><link rel="preload" as="image" href="./images/pipeline.png"/><link rel="preload" as="image" href="./images/architecture.png"/><link rel="preload" as="image" href="./images/training-loss.png"/><link rel="preload" as="image" href="./images/shade-variations.png"/><link rel="preload" as="image" href="./images/route-planning.png"/><link rel="stylesheet" href="/heatwave/_next/static/css/fdffdd60fdadacb1.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/heatwave/_next/static/chunks/webpack-206004022f65901c.js"/><script src="/heatwave/_next/static/chunks/4bd1b696-65f2dd90969a3b23.js" async=""></script><script src="/heatwave/_next/static/chunks/684-808b4f0f8ed25707.js" async=""></script><script src="/heatwave/_next/static/chunks/main-app-f7234dc5b7ce0e16.js" async=""></script><script src="/heatwave/_next/static/chunks/app/layout-571d362ee642807b.js" async=""></script><script src="/heatwave/_next/static/chunks/452-6d3aac88a29ebeec.js" async=""></script><script src="/heatwave/_next/static/chunks/app/page-c449dab788ec9911.js" async=""></script><title>DeepShade: Text-Conditioned Shade Simulation | IJCAI 2025</title><meta name="description" content="Enabling real-time urban shade prediction through AI-powered diffusion models to combat extreme heat and save lives"/><meta name="generator" content="v0.app"/><script src="/heatwave/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="antialiased"><main class="min-h-screen"><nav class="fixed top-0 left-0 right-0 z-50 transition-all duration-300" style="background:rgba(255, 255, 255, 0.8);backdrop-filter:blur(20px);-webkit-backdrop-filter:blur(20px);border-bottom:1px solid rgba(0,0,0,0.05);box-shadow:none"><div class="max-w-[1400px] mx-auto px-12 py-5"><div class="flex items-center justify-between"><a class="text-xl font-bold" style="color:#0f172a" href="/heatwave/">DeepShade</a><ul class="hidden md:flex items-center gap-8 list-none"><li><a href="#abstract" class="text-[15px] font-medium transition-colors duration-300 hover:text-[#2563eb]" style="color:#0f172a">Abstract</a></li><li><a href="#dataset" class="text-[15px] font-medium transition-colors duration-300 hover:text-[#2563eb]" style="color:#0f172a">Dataset</a></li><li><a href="#method" class="text-[15px] font-medium transition-colors duration-300 hover:text-[#2563eb]" style="color:#0f172a">Method</a></li><li><a href="#results" class="text-[15px] font-medium transition-colors duration-300 hover:text-[#2563eb]" style="color:#0f172a">Results</a></li><li><a href="#citation" class="text-[15px] font-medium transition-colors duration-300 hover:text-[#2563eb]" style="color:#0f172a">Citation</a></li></ul></div></div></nav><section class="pt-[200px] pb-20 px-12" style="background:linear-gradient(180deg, #f8fafc 0%, #ffffff 100%)"><div class="max-w-[1200px] mx-auto"><div class="inline-block px-5 py-2 mb-8 text-white text-xs font-semibold tracking-[1px] uppercase rounded-full" style="background:#0f172a">IJCAI 2025</div><h1 class="text-6xl font-bold leading-[1.1] mb-8" style="color:#0f172a;letter-spacing:-0.02em">DeepShade: Enable Shade Simulation by Text-conditioned Image Generation</h1><p class="text-2xl max-w-[800px] mb-12 leading-[1.5]" style="color:#64748b">Enabling real-time urban shade prediction through AI-powered diffusion models to combat extreme heat and save lives</p><p class="text-lg mb-4 leading-[1.8]" style="color:#475569">Longchao Da · Xiangrui Liu · Mithun Shivakoti · Thirulogasankar Pranav Kutralingam · Yezhou Yang · Hua Wei</p><p class="text-base mb-12" style="color:#94a3b8">Arizona State University</p><div class="flex flex-wrap gap-4"><a href="https://arxiv.org/pdf/2507.12103" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-2.5 px-8 py-4 text-[15px] font-semibold rounded-xl text-white transition-all duration-300" style="background:#0f172a"><span>Read Paper</span><span>→</span></a><a href="https://github.com/LongchaoDa/DeepShade" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-2.5 px-8 py-4 text-[15px] font-semibold rounded-xl bg-white transition-all duration-300" style="color:#0f172a;border:2px solid #e2e8f0">GitHub</a><a href="https://huggingface.co/datasets/DARL-ASU/DeepShade" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-2.5 px-8 py-4 text-[15px] font-semibold rounded-xl bg-white transition-all duration-300" style="color:#0f172a;border:2px solid #e2e8f0">Dataset</a><a href="#citation" class="inline-flex items-center gap-2.5 px-8 py-4 text-[15px] font-semibold rounded-xl bg-white transition-all duration-300" style="color:#0f172a;border:2px solid #e2e8f0">BibTeX</a></div></div></section><section id="abstract" class="py-[120px] px-12 bg-white"><div class="max-w-[1400px] mx-auto"><div class="text-center mb-16"><div class="text-sm font-semibold tracking-[2px] uppercase mb-4" style="color:#3b82f6">Overview</div><h2 class="text-5xl font-bold mb-6" style="color:#0f172a;letter-spacing:-0.02em">Abstract</h2></div><div class="max-w-[1000px] mx-auto"><p class="text-lg leading-[1.8] text-justify" style="color:#475569">Heatwaves pose a significant threat to public health, especially as global warming intensifies. However, current routing systems (e.g., online maps) fail to incorporate shade information due to the difficulty of estimating shades directly from noisy satellite imagery and the limited availability of training data for generative models. In this paper, we address these challenges through two main contributions. First, we build an extensive dataset covering diverse longitude-latitude regions, varying levels of building density, and different urban layouts. Leveraging Blender-based 3D simulations alongside building outlines, we capture building shadows under various solar zenith angles throughout the year and at different times of day. These simulated shadows are aligned with satellite images in terms of the areas, providing a rich resource for learning shade patterns. Second, we propose the DeepShade, a diffusion-based model designed to learn and synthesize shade variations over time. It emphasizes the nuance of edge features by jointly considering RGB with the Canny edge layer, and incorporates contrastive learning to capture the temporal change rules of shade. Then, by conditioning on textual descriptions of known conditions (e.g., time of day, solar angles), our framework provides improved performance in generating shade images.</p></div></div></section><section class="py-[120px] px-12" style="background:#0f172a;color:white"><div class="max-w-[1400px] mx-auto"><div class="text-center mb-16"><div class="text-sm font-semibold tracking-[2px] uppercase mb-4" style="color:#3b82f6">Live Demo</div><h2 class="text-5xl font-bold mb-6" style="letter-spacing:-0.02em">Shadow Movement Throughout the Day</h2><p class="text-xl max-w-[700px] mx-auto" style="color:#94a3b8">Watch real-time shade predictions as DeepShade simulates shadow patterns through different times of the day</p></div><div class="max-w-[1200px] mx-auto rounded-3xl overflow-hidden flex justify-center" style="box-shadow:0 40px 80px rgba(0,0,0,0.3)"><img src="./images/shadow-demo.gif" alt="DeepShade Shadow Simulation" class="rounded-2xl object-contain w-full max-w-4xl max-h-[600px]"/></div></div></section><section class="py-[120px] px-12 bg-white"><div class="max-w-[1200px] mx-auto"><div class="grid grid-cols-1 md:grid-cols-4 gap-12"><div class="text-center"><div class="text-[56px] font-bold leading-none mb-4" style="color:#2563eb">178K+</div><div class="text-base font-medium" style="color:#64748b">Annual Heat Deaths</div></div><div class="text-center"><div class="text-[56px] font-bold leading-none mb-4" style="color:#2563eb">12</div><div class="text-base font-medium" style="color:#64748b">Cities Tested</div></div><div class="text-center"><div class="text-[56px] font-bold leading-none mb-4" style="color:#2563eb">6</div><div class="text-base font-medium" style="color:#64748b">Countries Covered</div></div><div class="text-center"><div class="text-[56px] font-bold leading-none mb-4" style="color:#2563eb">70/30</div><div class="text-base font-medium" style="color:#64748b">Train/Test Split</div></div></div></div></section><section id="dataset" class="py-[120px] px-12" style="background:#f8fafc"><div class="max-w-[1400px] mx-auto"><div class="text-center mb-16"><div class="text-sm font-semibold tracking-[2px] uppercase mb-4" style="color:#3b82f6">Data Collection</div><h2 class="text-5xl font-bold mb-6" style="color:#0f172a;letter-spacing:-0.02em">Comprehensive Global Dataset</h2><p class="text-xl max-w-[700px] mx-auto" style="color:#94a3b8">A rigorous pipeline covering geographical diversity, urban layout variability, and traffic rule variations</p></div><div class="mb-16"><div class="rounded-2xl p-8 mx-auto" style="background:#ffffff;max-width:1200px;box-shadow:0 4px 12px rgba(0,0,0,0.05)"><div class="rounded-xl flex items-center justify-center" style="background:#f1f5f9;aspect-ratio:16/7"><img src="./images/pipeline.png" alt="Dataset Creation Pipeline" class="rounded-lg object-contain max-h-[400px] mx-auto"/></div><div class="text-center mt-4 text-sm font-mono" style="color:#64748b">Figure 1: Dataset Creation Pipeline</div></div></div><div class="grid md:grid-cols-3 gap-8 max-w-[1200px] mx-auto"><div class="bg-white p-8 rounded-2xl transition-shadow duration-300" style="box-shadow:0 4px 12px rgba(0,0,0,0.05)"><h4 class="text-xl font-semibold mb-4" style="color:#0f172a">Geographical Diversity</h4><p class="text-base leading-[1.6]" style="color:#64748b">Covers 12 cities across Asia, Americas, Europe, and Africa including Beijing, Phoenix, São Paulo, Madrid, Cairo, Mumbai, Xi&#x27;An, Tempe, Brasilia, Seville, Aswan, and Jaipur.</p></div><div class="bg-white p-8 rounded-2xl transition-shadow duration-300" style="box-shadow:0 4px 12px rgba(0,0,0,0.05)"><h4 class="text-xl font-semibold mb-4" style="color:#0f172a">Urban Layout Variability</h4><p class="text-base leading-[1.6]" style="color:#64748b">Captures diverse configurations from dense high-rise areas to sparse flat regions, ensuring model robustness across different building densities and architectural styles.</p></div><div class="bg-white p-8 rounded-2xl transition-shadow duration-300" style="box-shadow:0 4px 12px rgba(0,0,0,0.05)"><h4 class="text-xl font-semibold mb-4" style="color:#0f172a">Simulation Pipeline</h4><p class="text-base leading-[1.6]" style="color:#64748b">Uses Blender-based 3D rendering with OSM building data, aligned with Google Maps tile level 13, capturing shades at various solar angles and times throughout the year.</p></div></div></div></section><section id="method" class="py-[120px] px-12" style="background:#ffffff"><div class="max-w-[1400px] mx-auto"><div class="text-center mb-16"><div class="text-sm font-semibold tracking-[2px] uppercase mb-4" style="color:#3b82f6">Innovation</div><h2 class="text-5xl font-bold mb-6" style="color:#0f172a;letter-spacing:-0.02em">Edge-Enhanced Diffusion Architecture</h2><p class="text-xl max-w-[700px] mx-auto" style="color:#94a3b8">DeepShade combines cutting-edge computer vision with temporal learning</p></div><div class="mb-16"><div class="rounded-2xl p-8 mx-auto" style="background:#f8fafc;max-width:1200px"><div class="rounded-xl flex items-center justify-center" style="background:#f1f5f9;aspect-ratio:16/7"><img src="./images/architecture.png" alt="DeepShade Architecture" class="rounded-lg object-contain max-h-[400px] mx-auto"/></div><div class="text-center mt-4 text-sm font-mono" style="color:#64748b">Figure 2: DeepShade Architecture</div></div></div><div class="grid md:grid-cols-2 gap-12 max-w-[1200px] mx-auto"><div><h3 class="text-2xl font-bold mb-6" style="color:#0f172a">Edge-Enhanced Conditioning</h3><p class="text-base leading-[1.6] mb-6" style="color:#64748b">We concatenate RGB building skeleton with Canny edge features to form a 4-channel input (R, G, B, Edge), enabling the model to capture subtle shade boundaries with precision.</p><div class="p-6 rounded-xl" style="background:#f1f5f9;font-family:monospace;font-size:14px;color:#334155">x_cond = [x_sk_R, x_sk_G, x_sk_B, x_edge] ∈ ℝ^(H×W×4)</div></div><div><h3 class="text-2xl font-bold mb-6" style="color:#0f172a">Contrastive Learning</h3><p class="text-base leading-[1.6] mb-6" style="color:#64748b">Our contrastive framework enforces temporal consistency by distinguishing between shade patterns at different times, using InfoNCE loss to learn realistic shade evolution.</p><div class="p-6 rounded-xl" style="background:#f1f5f9;font-family:monospace;font-size:14px;color:#334155">L_total = L_ControlNet + 0.1×L_contrastive</div></div></div></div></section><section id="results" class="py-[120px] px-12" style="background:#0f172a"><div class="max-w-[1400px] mx-auto"><div class="text-center mb-16"><div class="text-sm font-semibold tracking-[2px] uppercase mb-4" style="color:#3b82f6">Performance</div><h2 class="text-5xl font-bold mb-6" style="color:#ffffff;letter-spacing:-0.02em">State-of-the-Art Results</h2><p class="text-xl max-w-[700px] mx-auto" style="color:#94a3b8">DeepShade outperforms all baseline methods across 12 cities worldwide</p></div><div class="mb-16"><div class="rounded-2xl p-8 mx-auto" style="background:#1e293b;max-width:900px"><h3 class="text-2xl font-bold mb-4" style="color:#ffffff">Training Convergence</h3><div class="rounded-xl flex items-center justify-center bg-[#f1f5f9] p-4"><img src="./images/training-loss.png" alt="Training Loss Curves" class="rounded-lg object-contain w-full max-w-3xl mx-auto"/></div><div class="text-center mt-4 text-sm font-mono" style="color:#94a3b8">Figure 3: Training Loss Curves</div></div></div><div class="space-y-12"></div></div></section><section class="py-[120px] px-12 bg-slate-50"><div class="max-w-[1400px] mx-auto"><div class="text-center mb-16"><div class="text-sm font-semibold tracking-[2px] uppercase text-[#3b82f6] mb-4">Ablation Study</div><h2 class="text-5xl font-bold mb-6 tracking-tight">Component Contributions</h2><p class="text-xl text-slate-500 max-w-[700px] mx-auto">Evaluating the importance of each component in DeepShade (tested on Tempe dataset)</p></div><div class="max-w-[1200px] mx-auto bg-white rounded-2xl overflow-hidden shadow-[0_20px_60px_rgba(0,0,0,0.05)]"><table class="w-full border-collapse"><thead><tr><th class="bg-[#0f172a] text-white text-sm font-semibold uppercase tracking-wider p-5 text-left">Model Configuration</th><th class="bg-[#0f172a] text-white text-sm font-semibold uppercase tracking-wider p-5 text-left">SSIM ↑</th><th class="bg-[#0f172a] text-white text-sm font-semibold uppercase tracking-wider p-5 text-left">mIoU ↑</th><th class="bg-[#0f172a] text-white text-sm font-semibold uppercase tracking-wider p-5 text-left">B-IoU ↑</th><th class="bg-[#0f172a] text-white text-sm font-semibold uppercase tracking-wider p-5 text-left">MSE ↓</th><th class="bg-[#0f172a] text-white text-sm font-semibold uppercase tracking-wider p-5 text-left">LPIPS ↓</th></tr></thead><tbody><tr class="hover:bg-slate-50 transition-colors"><td class="p-4 border-b border-slate-200 font-medium text-[#0f172a]">Backbone Model (Direct)</td><td class="p-4 border-b border-slate-200 text-[#0f172a]">0.4252 ± 0.01</td><td class="p-4 border-b border-slate-200 text-[#0f172a]">0.0358 ± 0.00</td><td class="p-4 border-b border-slate-200 text-[#0f172a]">0.0213 ± 0.00</td><td class="p-4 border-b border-slate-200 text-[#0f172a]">41.2666 ± 1.65</td><td class="p-4 border-b border-slate-200 text-[#0f172a]">0.7967 ± 0.00</td></tr><tr class="hover:bg-slate-50 transition-colors"><td class="p-4 border-b border-slate-200 font-medium text-[#0f172a]">Vanilla ControlNet</td><td class="p-4 border-b border-slate-200 text-[#0f172a]">0.9690 ± 0.04</td><td class="p-4 border-b border-slate-200 text-[#0f172a]">0.2736 ± 0.13</td><td class="p-4 border-b border-slate-200 text-[#0f172a]">0.0812 ± 0.05</td><td class="p-4 border-b border-slate-200 text-[#0f172a]">18.3388 ± 3.37</td><td class="p-4 border-b border-slate-200 text-[#0f172a]">0.3304 ± 0.03</td></tr><tr class="hover:bg-slate-50 transition-colors"><td class="p-4 border-b border-slate-200 font-medium text-[#0f172a]">+ Edge Conditioning</td><td class="p-4 border-b border-slate-200 text-[#0f172a]">0.9684 ± 0.01</td><td class="p-4 border-b border-slate-200 text-[#0f172a]">0.2898 ± 0.04</td><td class="p-4 border-b border-slate-200 text-[#0f172a]">0.1040 ± 0.01</td><td class="p-4 border-b border-slate-200 text-[#0f172a]">18.6686 ± 0.70</td><td class="p-4 border-b border-slate-200 text-[#0f172a]">0.3358 ± 0.01</td></tr><tr class="bg-slate-50"><td class="p-4 font-bold text-[#0f172a]">DeepShade (Full Model)</td><td class="p-4 text-green-600 font-bold">0.9692 ± 0.04</td><td class="p-4 text-green-600 font-bold">0.2903 ± 0.20</td><td class="p-4 text-green-600 font-bold">0.1240 ± 0.07</td><td class="p-4 text-green-600 font-bold">18.1721 ± 4.09</td><td class="p-4 text-green-600 font-bold">0.3024 ± 0.29</td></tr></tbody></table></div></div></section><section class="py-[120px] px-12 bg-slate-50"><div class="max-w-[1400px] mx-auto"><div class="text-center mb-16"><div class="text-sm font-semibold tracking-[2px] uppercase text-[#3b82f6] mb-4">Key Features</div><h2 class="text-5xl font-bold mb-6 tracking-tight">Why DeepShade Works</h2></div><div class="grid grid-cols-1 md:grid-cols-3 gap-8 max-w-[1200px] mx-auto"><div class="bg-white p-8 rounded-2xl shadow-[0_4px_12px_rgba(0,0,0,0.05)]"><h4 class="text-xl font-semibold mb-4 text-[#0f172a]">🎯 Edge-Enhanced Conditioning</h4><p class="text-base text-slate-600 leading-relaxed">Combines RGB satellite imagery with Canny edge detection (4-channel input) to capture precise building boundaries and shade edges, ensuring sharp and accurate shadow generation.</p></div><div class="bg-white p-8 rounded-2xl shadow-[0_4px_12px_rgba(0,0,0,0.05)]"><h4 class="text-xl font-semibold mb-4 text-[#0f172a]">⏱️ Temporal Consistency</h4><p class="text-base text-slate-600 leading-relaxed">Contrastive learning with InfoNCE loss enforces temporal rules - shadows from nearby time steps are more similar than distant ones, maintaining realistic shade progression throughout the day.</p></div><div class="bg-white p-8 rounded-2xl shadow-[0_4px_12px_rgba(0,0,0,0.05)]"><h4 class="text-xl font-semibold mb-4 text-[#0f172a]">🌍 Global Generalization</h4><p class="text-base text-slate-600 leading-relaxed">Trained on diverse cities across 3 continents with varying building densities and layouts, the model generalizes to unseen locations with only a satellite image - no LiDAR required.</p></div></div></div></section><section class="py-[120px] px-12 bg-white"><div class="max-w-[1400px] mx-auto"><div class="text-center mb-16"><div class="text-sm font-semibold tracking-[2px] uppercase text-[#3b82f6] mb-4">Technical Details</div><h2 class="text-5xl font-bold mb-6 tracking-tight">Model Architecture &amp; Training</h2></div><div class="grid grid-cols-1 md:grid-cols-2 gap-20 max-w-[1400px] mx-auto mt-16"><div><h3 class="text-3xl font-bold mb-6 text-[#0f172a]">Training Configuration</h3><ul class="space-y-0"><li class="text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4"><span class="text-[#2563eb] font-bold text-xl">→</span>Base model: ControlNet with Stable Diffusion backbone</li><li class="text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4"><span class="text-[#2563eb] font-bold text-xl">→</span>Input: 4-channel (RGB + Edge), 512×512 resolution</li><li class="text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4"><span class="text-[#2563eb] font-bold text-xl">→</span>Loss: L_total = L_ControlNet + 0.1×L_contrastive</li><li class="text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4"><span class="text-[#2563eb] font-bold text-xl">→</span>Temperature τ = 0.1 for InfoNCE loss</li><li class="text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4"><span class="text-[#2563eb] font-bold text-xl">→</span>Dataset split: 70% train, 30% test</li><li class="text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4"><span class="text-[#2563eb] font-bold text-xl">→</span>Training: 50 epochs, converges 3× faster than vanilla ControlNet</li></ul></div><div><h3 class="text-3xl font-bold mb-6 text-[#0f172a]">Data Pipeline</h3><ul class="space-y-0"><li class="text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4"><span class="text-[#2563eb] font-bold text-xl">→</span>Blender-based 3D simulation with OSM building data</li><li class="text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4"><span class="text-[#2563eb] font-bold text-xl">→</span>Aligned with Google Maps tile level 13</li><li class="text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4"><span class="text-[#2563eb] font-bold text-xl">→</span>Multiple solar angles and times captured per location</li><li class="text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4"><span class="text-[#2563eb] font-bold text-xl">→</span>Ground truth: x_gt = x_shade - x_skeleton - I(x_shade ≤ α)</li><li class="text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4"><span class="text-[#2563eb] font-bold text-xl">→</span>Positive pairs: same location, 1-hour temporal gap</li><li class="text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4"><span class="text-[#2563eb] font-bold text-xl">→</span>Contrastive buffer with balanced pos/neg sampling</li></ul></div></div></div></section><section class="py-[100px] px-12 bg-[#0f172a] text-white"><div class="max-w-[1400px] mx-auto"><div class="text-center mb-16"><div class="text-sm font-semibold tracking-[2px] uppercase text-[#3b82f6] mb-4">Visual Results</div><h2 class="text-5xl font-bold mb-6 tracking-tight">Generated Shade Examples</h2><p class="text-xl text-slate-400 max-w-[700px] mx-auto">DeepShade generates realistic shadows across diverse urban environments and times of day</p></div><div class="bg-[#1e293b] p-8 rounded-3xl max-w-[1200px] mx-auto"><img src="./images/shade-variations.png" alt="Shade variations throughout the day" class="rounded-2xl object-contain mx-auto"/><div class="text-center mt-4 text-sm font-mono text-slate-400">Figure 4: Shade orientation changes across different times of the day</div></div></div></section><section class="py-[120px] px-12 bg-slate-50"><div class="max-w-[1400px] mx-auto"><div class="text-center mb-16"><div class="text-sm font-semibold tracking-[2px] uppercase text-[#3b82f6] mb-4">Impact</div><h2 class="text-5xl font-bold mb-6 tracking-tight">Why This Matters</h2></div><div class="grid grid-cols-1 md:grid-cols-3 gap-8 max-w-[1200px] mx-auto"><div class="bg-white p-8 rounded-2xl shadow-[0_4px_12px_rgba(0,0,0,0.05)]"><h4 class="text-xl font-semibold mb-4 text-[#0f172a]">🌡️ Public Health Crisis</h4><p class="text-base text-slate-600 leading-relaxed">Over 178,700 people die annually from extreme heat. DeepShade enables shade-aware navigation to reduce heat exposure for vulnerable populations during heatwaves.</p></div><div class="bg-white p-8 rounded-2xl shadow-[0_4px_12px_rgba(0,0,0,0.05)]"><h4 class="text-xl font-semibold mb-4 text-[#0f172a]">🏙️ Urban Planning Tool</h4><p class="text-base text-slate-600 leading-relaxed">City planners can identify areas lacking shade coverage and optimize placement of cooling corridors, shade structures, and green infrastructure.</p></div><div class="bg-white p-8 rounded-2xl shadow-[0_4px_12px_rgba(0,0,0,0.05)]"><h4 class="text-xl font-semibold mb-4 text-[#0f172a]">📱 Scalable Solution</h4><p class="text-base text-slate-600 leading-relaxed">Unlike LiDAR-based methods, DeepShade only requires satellite imagery - enabling city-wide deployment at low cost with real-time updates.</p></div></div></div></section><section id="application" class="py-[120px] px-12" style="background:#ffffff"><div class="max-w-[1400px] mx-auto"><div class="text-center mb-16"><div class="text-sm font-semibold tracking-[2px] uppercase mb-4" style="color:#3b82f6">Real-World Impact</div><h2 class="text-5xl font-bold mb-6" style="color:#0f172a;letter-spacing:-0.02em">Shade-Aware Route Planning</h2><p class="text-xl max-w-[700px] mx-auto" style="color:#94a3b8">Protecting people from extreme heat through intelligent navigation</p></div><div class="mb-16"><div class="rounded-2xl p-8 mx-auto" style="background:#f8fafc;max-width:1200px"><div class="rounded-xl flex items-center justify-center bg-[#f1f5f9] p-4"><img src="./images/route-planning.png" alt="Route Planning Demonstration" class="rounded-lg object-contain w-full max-w-5xl mx-auto"/></div><div class="text-center mt-4 text-sm font-mono" style="color:#64748b">Figure 4: Route Planning Demonstration</div></div></div><div class="grid md:grid-cols-2 gap-12 max-w-[1200px] mx-auto"><div><h3 class="text-2xl font-bold mb-6" style="color:#0f172a">Real-World Application</h3><p class="text-base leading-[1.6] mb-6" style="color:#64748b">DeepShade has been integrated into a prototype routing system designed for deployment in urban environments prone to extreme heat. By combining real-time solar geometry simulation with AI-driven shade inference, the system provides safe and comfortable navigation options for pedestrians, cyclists, and drivers. This demonstrates DeepShade’s potential as a public-facing, data-driven tool for heat mitigation and sustainable urban design.</p><div class="space-y-4"><div class="p-4 rounded-xl" style="background:#f1f5f9"><div class="text-sm font-semibold mb-2" style="color:#0f172a">Input</div><div class="text-sm" style="color:#64748b">Real-time GPS coordinates, date, and time</div></div><div class="p-4 rounded-xl" style="background:#f1f5f9"><div class="text-sm font-semibold mb-2" style="color:#0f172a">Output</div><div class="text-sm" style="color:#64748b">Safe, shade-optimized navigation routes with interactive visual overlays</div></div></div></div><div><h3 class="text-2xl font-bold mb-6" style="color:#0f172a">Public Health Impact</h3><p class="text-base leading-[1.6] mb-6" style="color:#64748b">With over 178,700 annual deaths from extreme heat globally, shade-aware navigation can significantly reduce heat exposure for vulnerable populations including the elderly and outdoor workers.</p><div class="space-y-4"><div class="flex gap-4"><div class="w-12 h-12 rounded-xl flex items-center justify-center flex-shrink-0" style="background:#dbeafe"><span style="color:#3b82f6;font-size:20px">🌡️</span></div><div><div class="text-sm font-semibold mb-1" style="color:#0f172a">Heat Mitigation</div><div class="text-sm" style="color:#64748b">Reduce direct sun exposure during peak heat hours</div></div></div><div class="flex gap-4"><div class="w-12 h-12 rounded-xl flex items-center justify-center flex-shrink-0" style="background:#dcfce7"><span style="color:#10b981;font-size:20px">🗺️</span></div><div><div class="text-sm font-semibold mb-1" style="color:#0f172a">Urban Planning</div><div class="text-sm" style="color:#64748b">Identify areas needing artificial shade infrastructure</div></div></div><div class="flex gap-4"><div class="w-12 h-12 rounded-xl flex items-center justify-center flex-shrink-0" style="background:#fef3c7"><span style="color:#f59e0b;font-size:20px">⚡</span></div><div><div class="text-sm font-semibold mb-1" style="color:#0f172a">Real-Time Adaptation</div><div class="text-sm" style="color:#64748b">Dynamic routing based on time of day and solar angles</div></div></div></div></div></div></div></section><section class="py-[80px] px-12 bg-[#0f172a] text-white"><div class="max-w-[1400px] mx-auto"><div class="text-center mb-16"><div class="text-sm font-semibold tracking-[2px] uppercase text-[#3b82f6] mb-4">Resources</div><h2 class="text-5xl font-bold mb-6 tracking-tight">Get Started</h2></div><div class="grid grid-cols-1 md:grid-cols-3 gap-8 mt-12"><div class="bg-white/5 backdrop-blur-sm p-8 rounded-2xl text-center border border-white/10"><h4 class="text-xl font-semibold mb-4">📄 Paper</h4><p class="text-slate-300 mb-6 leading-relaxed">Read the full IJCAI 2025 paper with technical details and comprehensive experiments.</p><a href="https://arxiv.org/pdf/2507.12103" class="inline-flex items-center gap-2 px-8 py-4 bg-[#0f172a] text-white font-semibold rounded-xl hover:bg-[#1e293b] transition-all hover:-translate-y-0.5 hover:shadow-[0_20px_40px_rgba(0,0,0,0.15)]">arXiv PDF</a></div><div class="bg-white/5 backdrop-blur-sm p-8 rounded-2xl text-center border border-white/10"><h4 class="text-xl font-semibold mb-4">💻 Code</h4><p class="text-slate-300 mb-6 leading-relaxed">Access the complete codebase, training scripts, and inference notebooks on GitHub.</p><a href="https://github.com/LongchaoDa/DeepShade_repo" class="inline-flex items-center gap-2 px-8 py-4 bg-[#0f172a] text-white font-semibold rounded-xl hover:bg-[#1e293b] transition-all hover:-translate-y-0.5 hover:shadow-[0_20px_40px_rgba(0,0,0,0.15)]">GitHub Repo</a></div><div class="bg-white/5 backdrop-blur-sm p-8 rounded-2xl text-center border border-white/10"><h4 class="text-xl font-semibold mb-4">🗂️ Dataset</h4><p class="text-slate-300 mb-6 leading-relaxed">Download the comprehensive shade dataset covering 12 cities across 3 continents.</p><a href="https://huggingface.co/datasets/DARL-ASU/DeepShade" class="inline-flex items-center gap-2 px-8 py-4 bg-[#0f172a] text-white font-semibold rounded-xl hover:bg-[#1e293b] transition-all hover:-translate-y-0.5 hover:shadow-[0_20px_40px_rgba(0,0,0,0.15)]">HuggingFace</a></div></div></div></section><section class="py-[80px] px-12 bg-white"><div class="max-w-[1400px] mx-auto"><div class="text-center mb-16"><div class="text-sm font-semibold tracking-[2px] uppercase text-[#3b82f6] mb-4">Team</div><h2 class="text-5xl font-bold mb-6 tracking-tight">Authors</h2></div><div class="max-w-[900px] mx-auto text-center"><p class="text-lg text-slate-600 leading-loose mb-8"><strong>Longchao Da*</strong> · <strong>Xiangrui Liu*</strong> · Mithun Shivakoti · Thirulogasankar Pranav Kutralingam · Yezhou Yang · Hua Wei</p><p class="text-base text-slate-400 mb-4">(* Equal contribution)</p><p class="text-lg text-slate-600 font-semibold">Arizona State University</p><p class="text-base text-slate-400 mt-8">Presented at the International Joint Conference on Artificial Intelligence (IJCAI) 2025</p></div></div></section><section id="citation" class="py-20 px-6 lg:px-8" style="background:#0f172a"><div class="max-w-4xl mx-auto"><div class="text-center mb-12"><p class="text-sm font-semibold uppercase tracking-wide mb-3" style="color:#3b82f6">Citation</p><h2 class="text-3xl md:text-4xl font-bold mb-4" style="color:#ffffff">Use This Work</h2><p class="text-lg" style="color:#94a3b8">If you find DeepShade useful for your research, please cite our paper</p></div><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 border shadow-sm relative p-6 rounded-xl" style="background:#1e293b;border:1px solid #334155"><button data-slot="button" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent dark:hover:bg-accent/50 h-8 rounded-md px-3 has-[&gt;svg]:px-2.5 absolute top-4 right-4 gap-2 text-slate-300 hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-copy h-4 w-4"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg>Copy</button><pre class="text-xs md:text-sm font-mono overflow-x-auto leading-relaxed" style="color:#e2e8f0">@inproceedings{da2025deepshade,
  title     = {DeepShade: Enable Shade Simulation by Text-conditioned Image Generation},
  author    = {Da, Longchao and Liu, Xiangrui and Shivakoti, Mithun and 
               Kutralingam, Thirulogasankar Pranav and Yang, Yezhou and Wei, Hua},
  booktitle = {International Joint Conference on Artificial Intelligence (IJCAI)},
  year      = {2025}
}</pre></div></div></section><footer class="py-12 px-6 lg:px-8 border-t border-border bg-background"><div class="max-w-6xl mx-auto text-center space-y-4"><p class="text-sm text-muted-foreground">© 2025 Arizona State University • Contact:<!-- --> <a href="mailto:hua.wei@asu.edu" class="text-primary hover:underline">hua.wei@asu.edu</a></p><p class="text-xs text-muted-foreground">Built with care for advancing heat-resilient urban planning</p></div></footer></main><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--><script src="/heatwave/_next/static/chunks/webpack-206004022f65901c.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[7555,[],\"\"]\n3:I[1295,[],\"\"]\n4:I[9742,[\"177\",\"static/chunks/app/layout-571d362ee642807b.js\"],\"Analytics\"]\n5:I[2386,[\"452\",\"static/chunks/452-6d3aac88a29ebeec.js\",\"974\",\"static/chunks/app/page-c449dab788ec9911.js\"],\"Navigation\"]\n6:I[1369,[\"452\",\"static/chunks/452-6d3aac88a29ebeec.js\",\"974\",\"static/chunks/app/page-c449dab788ec9911.js\"],\"HeroSection\"]\n8:I[2790,[\"452\",\"static/chunks/452-6d3aac88a29ebeec.js\",\"974\",\"static/chunks/app/page-c449dab788ec9911.js\"],\"VideoShowcase\"]\n9:I[9335,[\"452\",\"static/chunks/452-6d3aac88a29ebeec.js\",\"974\",\"static/chunks/app/page-c449dab788ec9911.js\"],\"DatasetSection\"]\na:I[5950,[\"452\",\"static/chunks/452-6d3aac88a29ebeec.js\",\"974\",\"static/chunks/app/page-c449dab788ec9911.js\"],\"MethodSection\"]\nb:I[5245,[\"452\",\"static/chunks/452-6d3aac88a29ebeec.js\",\"974\",\"static/chunks/app/page-c449dab788ec9911.js\"],\"ResultsSection\"]\nc:I[6444,[\"452\",\"static/chunks/452-6d3aac88a29ebeec.js\",\"974\",\"static/chunks/app/page-c449dab788ec9911.js\"],\"VisualResultsSection\"]\nd:I[5,[\"452\",\"static/chunks/452-6d3aac88a29ebeec.js\",\"974\",\"static/chunks/app/page-c449dab788ec9911.js\"],\"ApplicationSection\"]\ne:I[6320,[\"452\",\"static/chunks/452-6d3aac88a29ebeec.js\",\"974\",\"static/chunks/app/page-c449dab788ec9911.js\"],\"CitationSection\"]\nf:I[9665,[],\"OutletBoundary\"]\n12:I[9665,[],\"ViewportBoundary\"]\n14:I[9665,[],\"MetadataBoundary\"]\n16:I[6614,[],\"\"]\n:HL[\"/heatwave/_next/static/css/fdffdd60fdadacb1.css\",\"style\"]\n7:T545,Heatwaves pose a significant threat to public health, especially as global warming intensifies. However, current routing systems (e.g., online maps) fail to incorporate shade information due to the difficulty of estimating shades directly from noisy satellite imagery and the limited availability of training data for generative models. In this paper, we address these challenges through two main contributions. First, we build an extensive dataset covering diverse longitude-latitude regions, varying levels of building density, and different urban layouts. Leveraging Blender-based 3D simulations alo"])</script><script>self.__next_f.push([1,"ngside building outlines, we capture building shadows under various solar zenith angles throughout the year and at different times of day. These simulated shadows are aligned with satellite images in terms of the areas, providing a rich resource for learning shade patterns. Second, we propose the DeepShade, a diffusion-based model designed to learn and synthesize shade variations over time. It emphasizes the nuance of edge features by jointly considering RGB with the Canny edge layer, and incorporates contrastive learning to capture the temporal change rules of shade. Then, by conditioning on textual descriptions of known conditions (e.g., time of day, solar angles), our framework provides improved performance in generating shade images."])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"EmpNO0C4PEIYlk162BdEn\",\"p\":\"/heatwave\",\"c\":[\"\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/heatwave/_next/static/css/fdffdd60fdadacb1.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"antialiased\",\"children\":[[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}],[\"$\",\"$L4\",null,{}]]}]}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"main\",null,{\"className\":\"min-h-screen\",\"children\":[[\"$\",\"$L5\",null,{}],[\"$\",\"$L6\",null,{}],[\"$\",\"section\",null,{\"id\":\"abstract\",\"className\":\"py-[120px] px-12 bg-white\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-[1400px] mx-auto\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-center mb-16\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-sm font-semibold tracking-[2px] uppercase mb-4\",\"style\":{\"color\":\"#3b82f6\"},\"children\":\"Overview\"}],[\"$\",\"h2\",null,{\"className\":\"text-5xl font-bold mb-6\",\"style\":{\"color\":\"#0f172a\",\"letterSpacing\":\"-0.02em\"},\"children\":\"Abstract\"}]]}],[\"$\",\"div\",null,{\"className\":\"max-w-[1000px] mx-auto\",\"children\":[\"$\",\"p\",null,{\"className\":\"text-lg leading-[1.8] text-justify\",\"style\":{\"color\":\"#475569\"},\"children\":\"$7\"}]}]]}]}],[\"$\",\"$L8\",null,{}],[\"$\",\"section\",null,{\"className\":\"py-[120px] px-12 bg-white\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-[1200px] mx-auto\",\"children\":[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 md:grid-cols-4 gap-12\",\"children\":[[\"$\",\"div\",\"0\",{\"className\":\"text-center\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-[56px] font-bold leading-none mb-4\",\"style\":{\"color\":\"#2563eb\"},\"children\":\"178K+\"}],[\"$\",\"div\",null,{\"className\":\"text-base font-medium\",\"style\":{\"color\":\"#64748b\"},\"children\":\"Annual Heat Deaths\"}]]}],[\"$\",\"div\",\"1\",{\"className\":\"text-center\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-[56px] font-bold leading-none mb-4\",\"style\":{\"color\":\"#2563eb\"},\"children\":\"12\"}],[\"$\",\"div\",null,{\"className\":\"text-base font-medium\",\"style\":{\"color\":\"#64748b\"},\"children\":\"Cities Tested\"}]]}],[\"$\",\"div\",\"2\",{\"className\":\"text-center\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-[56px] font-bold leading-none mb-4\",\"style\":{\"color\":\"#2563eb\"},\"children\":\"6\"}],[\"$\",\"div\",null,{\"className\":\"text-base font-medium\",\"style\":{\"color\":\"#64748b\"},\"children\":\"Countries Covered\"}]]}],[\"$\",\"div\",\"3\",{\"className\":\"text-center\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-[56px] font-bold leading-none mb-4\",\"style\":{\"color\":\"#2563eb\"},\"children\":\"70/30\"}],[\"$\",\"div\",null,{\"className\":\"text-base font-medium\",\"style\":{\"color\":\"#64748b\"},\"children\":\"Train/Test Split\"}]]}]]}]}]}],[\"$\",\"$L9\",null,{}],[\"$\",\"$La\",null,{}],[\"$\",\"$Lb\",null,{}],[\"$\",\"section\",null,{\"className\":\"py-[120px] px-12 bg-slate-50\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-[1400px] mx-auto\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-center mb-16\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-sm font-semibold tracking-[2px] uppercase text-[#3b82f6] mb-4\",\"children\":\"Ablation Study\"}],[\"$\",\"h2\",null,{\"className\":\"text-5xl font-bold mb-6 tracking-tight\",\"children\":\"Component Contributions\"}],[\"$\",\"p\",null,{\"className\":\"text-xl text-slate-500 max-w-[700px] mx-auto\",\"children\":\"Evaluating the importance of each component in DeepShade (tested on Tempe dataset)\"}]]}],[\"$\",\"div\",null,{\"className\":\"max-w-[1200px] mx-auto bg-white rounded-2xl overflow-hidden shadow-[0_20px_60px_rgba(0,0,0,0.05)]\",\"children\":[\"$\",\"table\",null,{\"className\":\"w-full border-collapse\",\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"className\":\"bg-[#0f172a] text-white text-sm font-semibold uppercase tracking-wider p-5 text-left\",\"children\":\"Model Configuration\"}],[\"$\",\"th\",null,{\"className\":\"bg-[#0f172a] text-white text-sm font-semibold uppercase tracking-wider p-5 text-left\",\"children\":\"SSIM ↑\"}],[\"$\",\"th\",null,{\"className\":\"bg-[#0f172a] text-white text-sm font-semibold uppercase tracking-wider p-5 text-left\",\"children\":\"mIoU ↑\"}],[\"$\",\"th\",null,{\"className\":\"bg-[#0f172a] text-white text-sm font-semibold uppercase tracking-wider p-5 text-left\",\"children\":\"B-IoU ↑\"}],[\"$\",\"th\",null,{\"className\":\"bg-[#0f172a] text-white text-sm font-semibold uppercase tracking-wider p-5 text-left\",\"children\":\"MSE ↓\"}],[\"$\",\"th\",null,{\"className\":\"bg-[#0f172a] text-white text-sm font-semibold uppercase tracking-wider p-5 text-left\",\"children\":\"LPIPS ↓\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"className\":\"hover:bg-slate-50 transition-colors\",\"children\":[[\"$\",\"td\",null,{\"className\":\"p-4 border-b border-slate-200 font-medium text-[#0f172a]\",\"children\":\"Backbone Model (Direct)\"}],[\"$\",\"td\",null,{\"className\":\"p-4 border-b border-slate-200 text-[#0f172a]\",\"children\":\"0.4252 ± 0.01\"}],[\"$\",\"td\",null,{\"className\":\"p-4 border-b border-slate-200 text-[#0f172a]\",\"children\":\"0.0358 ± 0.00\"}],[\"$\",\"td\",null,{\"className\":\"p-4 border-b border-slate-200 text-[#0f172a]\",\"children\":\"0.0213 ± 0.00\"}],[\"$\",\"td\",null,{\"className\":\"p-4 border-b border-slate-200 text-[#0f172a]\",\"children\":\"41.2666 ± 1.65\"}],[\"$\",\"td\",null,{\"className\":\"p-4 border-b border-slate-200 text-[#0f172a]\",\"children\":\"0.7967 ± 0.00\"}]]}],[\"$\",\"tr\",null,{\"className\":\"hover:bg-slate-50 transition-colors\",\"children\":[[\"$\",\"td\",null,{\"className\":\"p-4 border-b border-slate-200 font-medium text-[#0f172a]\",\"children\":\"Vanilla ControlNet\"}],[\"$\",\"td\",null,{\"className\":\"p-4 border-b border-slate-200 text-[#0f172a]\",\"children\":\"0.9690 ± 0.04\"}],[\"$\",\"td\",null,{\"className\":\"p-4 border-b border-slate-200 text-[#0f172a]\",\"children\":\"0.2736 ± 0.13\"}],[\"$\",\"td\",null,{\"className\":\"p-4 border-b border-slate-200 text-[#0f172a]\",\"children\":\"0.0812 ± 0.05\"}],[\"$\",\"td\",null,{\"className\":\"p-4 border-b border-slate-200 text-[#0f172a]\",\"children\":\"18.3388 ± 3.37\"}],[\"$\",\"td\",null,{\"className\":\"p-4 border-b border-slate-200 text-[#0f172a]\",\"children\":\"0.3304 ± 0.03\"}]]}],[\"$\",\"tr\",null,{\"className\":\"hover:bg-slate-50 transition-colors\",\"children\":[[\"$\",\"td\",null,{\"className\":\"p-4 border-b border-slate-200 font-medium text-[#0f172a]\",\"children\":\"+ Edge Conditioning\"}],[\"$\",\"td\",null,{\"className\":\"p-4 border-b border-slate-200 text-[#0f172a]\",\"children\":\"0.9684 ± 0.01\"}],[\"$\",\"td\",null,{\"className\":\"p-4 border-b border-slate-200 text-[#0f172a]\",\"children\":\"0.2898 ± 0.04\"}],[\"$\",\"td\",null,{\"className\":\"p-4 border-b border-slate-200 text-[#0f172a]\",\"children\":\"0.1040 ± 0.01\"}],[\"$\",\"td\",null,{\"className\":\"p-4 border-b border-slate-200 text-[#0f172a]\",\"children\":\"18.6686 ± 0.70\"}],[\"$\",\"td\",null,{\"className\":\"p-4 border-b border-slate-200 text-[#0f172a]\",\"children\":\"0.3358 ± 0.01\"}]]}],[\"$\",\"tr\",null,{\"className\":\"bg-slate-50\",\"children\":[[\"$\",\"td\",null,{\"className\":\"p-4 font-bold text-[#0f172a]\",\"children\":\"DeepShade (Full Model)\"}],[\"$\",\"td\",null,{\"className\":\"p-4 text-green-600 font-bold\",\"children\":\"0.9692 ± 0.04\"}],[\"$\",\"td\",null,{\"className\":\"p-4 text-green-600 font-bold\",\"children\":\"0.2903 ± 0.20\"}],[\"$\",\"td\",null,{\"className\":\"p-4 text-green-600 font-bold\",\"children\":\"0.1240 ± 0.07\"}],[\"$\",\"td\",null,{\"className\":\"p-4 text-green-600 font-bold\",\"children\":\"18.1721 ± 4.09\"}],[\"$\",\"td\",null,{\"className\":\"p-4 text-green-600 font-bold\",\"children\":\"0.3024 ± 0.29\"}]]}]]}]]}]}]]}]}],[\"$\",\"section\",null,{\"className\":\"py-[120px] px-12 bg-slate-50\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-[1400px] mx-auto\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-center mb-16\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-sm font-semibold tracking-[2px] uppercase text-[#3b82f6] mb-4\",\"children\":\"Key Features\"}],[\"$\",\"h2\",null,{\"className\":\"text-5xl font-bold mb-6 tracking-tight\",\"children\":\"Why DeepShade Works\"}]]}],[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 md:grid-cols-3 gap-8 max-w-[1200px] mx-auto\",\"children\":[[\"$\",\"div\",null,{\"className\":\"bg-white p-8 rounded-2xl shadow-[0_4px_12px_rgba(0,0,0,0.05)]\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-xl font-semibold mb-4 text-[#0f172a]\",\"children\":\"🎯 Edge-Enhanced Conditioning\"}],[\"$\",\"p\",null,{\"className\":\"text-base text-slate-600 leading-relaxed\",\"children\":\"Combines RGB satellite imagery with Canny edge detection (4-channel input) to capture precise building boundaries and shade edges, ensuring sharp and accurate shadow generation.\"}]]}],[\"$\",\"div\",null,{\"className\":\"bg-white p-8 rounded-2xl shadow-[0_4px_12px_rgba(0,0,0,0.05)]\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-xl font-semibold mb-4 text-[#0f172a]\",\"children\":\"⏱️ Temporal Consistency\"}],[\"$\",\"p\",null,{\"className\":\"text-base text-slate-600 leading-relaxed\",\"children\":\"Contrastive learning with InfoNCE loss enforces temporal rules - shadows from nearby time steps are more similar than distant ones, maintaining realistic shade progression throughout the day.\"}]]}],[\"$\",\"div\",null,{\"className\":\"bg-white p-8 rounded-2xl shadow-[0_4px_12px_rgba(0,0,0,0.05)]\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-xl font-semibold mb-4 text-[#0f172a]\",\"children\":\"🌍 Global Generalization\"}],[\"$\",\"p\",null,{\"className\":\"text-base text-slate-600 leading-relaxed\",\"children\":\"Trained on diverse cities across 3 continents with varying building densities and layouts, the model generalizes to unseen locations with only a satellite image - no LiDAR required.\"}]]}]]}]]}]}],[\"$\",\"section\",null,{\"className\":\"py-[120px] px-12 bg-white\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-[1400px] mx-auto\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-center mb-16\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-sm font-semibold tracking-[2px] uppercase text-[#3b82f6] mb-4\",\"children\":\"Technical Details\"}],[\"$\",\"h2\",null,{\"className\":\"text-5xl font-bold mb-6 tracking-tight\",\"children\":\"Model Architecture \u0026 Training\"}]]}],[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 md:grid-cols-2 gap-20 max-w-[1400px] mx-auto mt-16\",\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-3xl font-bold mb-6 text-[#0f172a]\",\"children\":\"Training Configuration\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-0\",\"children\":[[\"$\",\"li\",\"0\",{\"className\":\"text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-[#2563eb] font-bold text-xl\",\"children\":\"→\"}],\"Base model: ControlNet with Stable Diffusion backbone\"]}],[\"$\",\"li\",\"1\",{\"className\":\"text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-[#2563eb] font-bold text-xl\",\"children\":\"→\"}],\"Input: 4-channel (RGB + Edge), 512×512 resolution\"]}],[\"$\",\"li\",\"2\",{\"className\":\"text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-[#2563eb] font-bold text-xl\",\"children\":\"→\"}],\"Loss: L_total = L_ControlNet + 0.1×L_contrastive\"]}],[\"$\",\"li\",\"3\",{\"className\":\"text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-[#2563eb] font-bold text-xl\",\"children\":\"→\"}],\"Temperature τ = 0.1 for InfoNCE loss\"]}],[\"$\",\"li\",\"4\",{\"className\":\"text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-[#2563eb] font-bold text-xl\",\"children\":\"→\"}],\"Dataset split: 70% train, 30% test\"]}],[\"$\",\"li\",\"5\",{\"className\":\"text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-[#2563eb] font-bold text-xl\",\"children\":\"→\"}],\"Training: 50 epochs, converges 3× faster than vanilla ControlNet\"]}]]}]]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-3xl font-bold mb-6 text-[#0f172a]\",\"children\":\"Data Pipeline\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-0\",\"children\":[[\"$\",\"li\",\"0\",{\"className\":\"text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-[#2563eb] font-bold text-xl\",\"children\":\"→\"}],\"Blender-based 3D simulation with OSM building data\"]}],[\"$\",\"li\",\"1\",{\"className\":\"text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-[#2563eb] font-bold text-xl\",\"children\":\"→\"}],\"Aligned with Google Maps tile level 13\"]}],[\"$\",\"li\",\"2\",{\"className\":\"text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-[#2563eb] font-bold text-xl\",\"children\":\"→\"}],\"Multiple solar angles and times captured per location\"]}],[\"$\",\"li\",\"3\",{\"className\":\"text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-[#2563eb] font-bold text-xl\",\"children\":\"→\"}],\"Ground truth: x_gt = x_shade - x_skeleton - I(x_shade ≤ α)\"]}],[\"$\",\"li\",\"4\",{\"className\":\"text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-[#2563eb] font-bold text-xl\",\"children\":\"→\"}],\"Positive pairs: same location, 1-hour temporal gap\"]}],[\"$\",\"li\",\"5\",{\"className\":\"text-base text-slate-600 py-4 border-b border-slate-200 flex items-center gap-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-[#2563eb] font-bold text-xl\",\"children\":\"→\"}],\"Contrastive buffer with balanced pos/neg sampling\"]}]]}]]}]]}]]}]}],[\"$\",\"$Lc\",null,{}],[\"$\",\"section\",null,{\"className\":\"py-[120px] px-12 bg-slate-50\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-[1400px] mx-auto\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-center mb-16\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-sm font-semibold tracking-[2px] uppercase text-[#3b82f6] mb-4\",\"children\":\"Impact\"}],[\"$\",\"h2\",null,{\"className\":\"text-5xl font-bold mb-6 tracking-tight\",\"children\":\"Why This Matters\"}]]}],[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 md:grid-cols-3 gap-8 max-w-[1200px] mx-auto\",\"children\":[[\"$\",\"div\",null,{\"className\":\"bg-white p-8 rounded-2xl shadow-[0_4px_12px_rgba(0,0,0,0.05)]\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-xl font-semibold mb-4 text-[#0f172a]\",\"children\":\"🌡️ Public Health Crisis\"}],[\"$\",\"p\",null,{\"className\":\"text-base text-slate-600 leading-relaxed\",\"children\":\"Over 178,700 people die annually from extreme heat. DeepShade enables shade-aware navigation to reduce heat exposure for vulnerable populations during heatwaves.\"}]]}],[\"$\",\"div\",null,{\"className\":\"bg-white p-8 rounded-2xl shadow-[0_4px_12px_rgba(0,0,0,0.05)]\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-xl font-semibold mb-4 text-[#0f172a]\",\"children\":\"🏙️ Urban Planning Tool\"}],[\"$\",\"p\",null,{\"className\":\"text-base text-slate-600 leading-relaxed\",\"children\":\"City planners can identify areas lacking shade coverage and optimize placement of cooling corridors, shade structures, and green infrastructure.\"}]]}],[\"$\",\"div\",null,{\"className\":\"bg-white p-8 rounded-2xl shadow-[0_4px_12px_rgba(0,0,0,0.05)]\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-xl font-semibold mb-4 text-[#0f172a]\",\"children\":\"📱 Scalable Solution\"}],[\"$\",\"p\",null,{\"className\":\"text-base text-slate-600 leading-relaxed\",\"children\":\"Unlike LiDAR-based methods, DeepShade only requires satellite imagery - enabling city-wide deployment at low cost with real-time updates.\"}]]}]]}]]}]}],[\"$\",\"$Ld\",null,{}],[\"$\",\"section\",null,{\"className\":\"py-[80px] px-12 bg-[#0f172a] text-white\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-[1400px] mx-auto\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-center mb-16\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-sm font-semibold tracking-[2px] uppercase text-[#3b82f6] mb-4\",\"children\":\"Resources\"}],[\"$\",\"h2\",null,{\"className\":\"text-5xl font-bold mb-6 tracking-tight\",\"children\":\"Get Started\"}]]}],[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 md:grid-cols-3 gap-8 mt-12\",\"children\":[[\"$\",\"div\",null,{\"className\":\"bg-white/5 backdrop-blur-sm p-8 rounded-2xl text-center border border-white/10\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-xl font-semibold mb-4\",\"children\":\"📄 Paper\"}],[\"$\",\"p\",null,{\"className\":\"text-slate-300 mb-6 leading-relaxed\",\"children\":\"Read the full IJCAI 2025 paper with technical details and comprehensive experiments.\"}],[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/pdf/2507.12103\",\"className\":\"inline-flex items-center gap-2 px-8 py-4 bg-[#0f172a] text-white font-semibold rounded-xl hover:bg-[#1e293b] transition-all hover:-translate-y-0.5 hover:shadow-[0_20px_40px_rgba(0,0,0,0.15)]\",\"children\":\"arXiv PDF\"}]]}],[\"$\",\"div\",null,{\"className\":\"bg-white/5 backdrop-blur-sm p-8 rounded-2xl text-center border border-white/10\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-xl font-semibold mb-4\",\"children\":\"💻 Code\"}],[\"$\",\"p\",null,{\"className\":\"text-slate-300 mb-6 leading-relaxed\",\"children\":\"Access the complete codebase, training scripts, and inference notebooks on GitHub.\"}],[\"$\",\"a\",null,{\"href\":\"https://github.com/LongchaoDa/DeepShade_repo\",\"className\":\"inline-flex items-center gap-2 px-8 py-4 bg-[#0f172a] text-white font-semibold rounded-xl hover:bg-[#1e293b] transition-all hover:-translate-y-0.5 hover:shadow-[0_20px_40px_rgba(0,0,0,0.15)]\",\"children\":\"GitHub Repo\"}]]}],[\"$\",\"div\",null,{\"className\":\"bg-white/5 backdrop-blur-sm p-8 rounded-2xl text-center border border-white/10\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-xl font-semibold mb-4\",\"children\":\"🗂️ Dataset\"}],[\"$\",\"p\",null,{\"className\":\"text-slate-300 mb-6 leading-relaxed\",\"children\":\"Download the comprehensive shade dataset covering 12 cities across 3 continents.\"}],[\"$\",\"a\",null,{\"href\":\"https://huggingface.co/datasets/DARL-ASU/DeepShade\",\"className\":\"inline-flex items-center gap-2 px-8 py-4 bg-[#0f172a] text-white font-semibold rounded-xl hover:bg-[#1e293b] transition-all hover:-translate-y-0.5 hover:shadow-[0_20px_40px_rgba(0,0,0,0.15)]\",\"children\":\"HuggingFace\"}]]}]]}]]}]}],[\"$\",\"section\",null,{\"className\":\"py-[80px] px-12 bg-white\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-[1400px] mx-auto\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-center mb-16\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-sm font-semibold tracking-[2px] uppercase text-[#3b82f6] mb-4\",\"children\":\"Team\"}],[\"$\",\"h2\",null,{\"className\":\"text-5xl font-bold mb-6 tracking-tight\",\"children\":\"Authors\"}]]}],[\"$\",\"div\",null,{\"className\":\"max-w-[900px] mx-auto text-center\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-lg text-slate-600 leading-loose mb-8\",\"children\":[[\"$\",\"strong\",null,{\"children\":\"Longchao Da*\"}],\" · \",[\"$\",\"strong\",null,{\"children\":\"Xiangrui Liu*\"}],\" · Mithun Shivakoti · Thirulogasankar Pranav Kutralingam · Yezhou Yang · Hua Wei\"]}],[\"$\",\"p\",null,{\"className\":\"text-base text-slate-400 mb-4\",\"children\":\"(* Equal contribution)\"}],[\"$\",\"p\",null,{\"className\":\"text-lg text-slate-600 font-semibold\",\"children\":\"Arizona State University\"}],[\"$\",\"p\",null,{\"className\":\"text-base text-slate-400 mt-8\",\"children\":\"Presented at the International Joint Conference on Artificial Intelligence (IJCAI) 2025\"}]]}]]}]}],[\"$\",\"$Le\",null,{}],[\"$\",\"footer\",null,{\"className\":\"py-12 px-6 lg:px-8 border-t border-border bg-background\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-6xl mx-auto text-center space-y-4\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground\",\"children\":[\"© 2025 Arizona State University • Contact:\",\" \",[\"$\",\"a\",null,{\"href\":\"mailto:hua.wei@asu.edu\",\"className\":\"text-primary hover:underline\",\"children\":\"hua.wei@asu.edu\"}]]}],[\"$\",\"p\",null,{\"className\":\"text-xs text-muted-foreground\",\"children\":\"Built with care for advancing heat-resilient urban planning\"}]]}]}]]}],\"$undefined\",null,[\"$\",\"$Lf\",null,{\"children\":[\"$L10\",\"$L11\",null]}]]}],{},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"GApFa-Ac4QuhgtvFbhOkY\",{\"children\":[[\"$\",\"$L12\",null,{\"children\":\"$L13\"}],null]}],[\"$\",\"$L14\",null,{\"children\":\"$L15\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$16\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"13:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n10:null\n"])</script><script>self.__next_f.push([1,"11:null\n15:[[\"$\",\"title\",\"0\",{\"children\":\"DeepShade: Text-Conditioned Shade Simulation | IJCAI 2025\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Enabling real-time urban shade prediction through AI-powered diffusion models to combat extreme heat and save lives\"}],[\"$\",\"meta\",\"2\",{\"name\":\"generator\",\"content\":\"v0.app\"}]]\n"])</script></body></html>